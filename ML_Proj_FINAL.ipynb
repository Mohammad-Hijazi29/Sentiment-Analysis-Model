{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohammad-Hijazi29/Sentiment-Analysis-Model/blob/main/ML_Proj_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis Project\n",
        "\n"
      ],
      "metadata": {
        "id": "gt17YJurn62M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing the necessary libraries and download the \"stopwords\" dataset from NLTK\n"
      ],
      "metadata": {
        "id": "XdZ7G9lh2-Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk, re, string\n",
        "from nltk.corpus import stopwords, twitter_samples\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n"
      ],
      "metadata": {
        "id": "WxqZ12xd3Bth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Dataset 1\n",
        "5,000 negative tweets and 5,000 positive tweets"
      ],
      "metadata": {
        "id": "VfILwqwHau7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('twitter_samples')\n",
        "\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "metadata": {
        "id": "5-RdI-rNatfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Dataset 2\n",
        "\n",
        "10,000 thousand positive tweets and 10,000 negative tweets\n"
      ],
      "metadata": {
        "id": "69uZavUsbS7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "positive_df = pd.read_excel('positive_tweets.xlsx', header=None, dtype=str)\n",
        "negative_df = pd.read_excel('negative_tweets.xlsx', header=None, dtype=str)\n",
        "\n",
        "\n",
        "all_positive_tweets = positive_df[0].astype(str).tolist()\n",
        "all_negative_tweets = negative_df[0].astype(str).tolist()"
      ],
      "metadata": {
        "id": "g19wy9ZbbQxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-process the data\n",
        "Remove retweets, URLs, hashtags, reduces long words, removes handles, filters out stopwords, and reduces words to root form."
      ],
      "metadata": {
        "id": "Sl1I9eK73IIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def is_number(word):\n",
        "    if word.isdigit():\n",
        "        return True\n",
        "\n",
        "    try:\n",
        "        float(word)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "    if re.match(r\"^[+-]?\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?$\", word):\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "words = [\"123\", \"123.45\", \"1,000\", \"-123.45\", \"3.14e2\", \"abc\"]\n",
        "for word in words:\n",
        "    if is_number(word):\n",
        "        print(f\"{word} is a number.\")\n",
        "    else:\n",
        "        print(f\"{word} is not a number.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcTE2TdyhJwW",
        "outputId": "8ece04df-af57-4804-c1c2-07839d5baf77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "123 is a number.\n",
            "123.45 is a number.\n",
            "1,000 is a number.\n",
            "-123.45 is a number.\n",
            "3.14e2 is a number.\n",
            "abc is not a number.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tweet(tweet):\n",
        "    stemmer = nltk.PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    tokenizer = nltk.TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and\n",
        "                word not in string.punctuation and is_number(word)==False):\n",
        "            stem_word = stemmer.stem(word)\n",
        "            tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean"
      ],
      "metadata": {
        "id": "6MlATNTC3Jkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count how many times each word was mentioned in positive and negative tweets.\n",
        "\n",
        "    Input:\n",
        "        tweets: a list of tweets\n",
        "        ys: an m x 1 array with the sentiment label of each tweet\n",
        "            (either 0 or 1)\n",
        "    Output:\n",
        "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
        "        frequency\n",
        "  \n",
        "  --> You are outputting the reduced frequency list as such:\n",
        "  { ('happy', 1) : 1, ('sad', 0) : 2 }"
      ],
      "metadata": {
        "id": "6j0Vjj6N3bH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_freqs(tweets, ys):\n",
        "    yslist = np.squeeze(ys).tolist()\n",
        "    freqs = {}\n",
        "    for y, tweet in zip(yslist, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, y)\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1\n",
        "    return freqs"
      ],
      "metadata": {
        "id": "ERA06jZP3d9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the above code"
      ],
      "metadata": {
        "id": "cQuf_KOm4F0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = ['i not happy','i am too tricked', 'i am sad', 'i am tired', 'i am tired']\n",
        "ys = [1, 0, 0, 0, 0]\n",
        "res = build_freqs(tweets, ys)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1LQY3mO4GAH",
        "outputId": "e587be4c-6d5d-401f-e0de-e202c376a3bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('happi', 1): 1, ('trick', 0): 1, ('sad', 0): 1, ('tire', 0): 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting Data for Training and Testing\n",
        "\n",
        "First 4000 set for training and last 1000 set for testing (Data set 1).\n",
        "\n",
        "First 8000 set for training and last 2000 set for testing (Data set 2)."
      ],
      "metadata": {
        "id": "7ExxuRJ54PcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos = all_positive_tweets[:8000]\n",
        "train_neg = all_negative_tweets[:8000]\n",
        "test_pos = all_positive_tweets[8000:]\n",
        "test_neg = all_negative_tweets[8000:]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n",
        "\n",
        "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
      ],
      "metadata": {
        "id": "uT1CXxv54Pj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create Frequency Dictionary"
      ],
      "metadata": {
        "id": "Ra0P7xIF4xMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = build_freqs(train_x, train_y)\n",
        "print(\"len(freqs) = \" + str(len(freqs.keys())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ln8JEwQ4xVe",
        "outputId": "16cbca85-1b29-4631-b1d1-26033e616dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(freqs) = 19300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the above data splitting"
      ],
      "metadata": {
        "id": "Q4AiEMeR4_eT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is an example of a positive tweet: \\n', train_x[22])\n",
        "print('\\nThis is an example of the processed version of the tweet: \\n', process_tweet(train_x[22]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaweyvlT5B_r",
        "outputId": "96618c12-9e46-4ea6-dacc-bd9874f1cdc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is an example of a positive tweet: \n",
            " @blitzmegaplex u're just teasing me, right? Well, I'm sold! Is waiting for the 21.30 show @ GI \n",
            "\n",
            "This is an example of the processed version of the tweet: \n",
            " [\"u'r\", 'teas', 'right', 'well', \"i'm\", 'sold', 'wait', 'show', 'gi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting the Features\n",
        "\n",
        "    Input:\n",
        "        tweet: a list of words for one tweet\n",
        "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "    Output:\n",
        "        x: a feature vector of dimension (1,3)"
      ],
      "metadata": {
        "id": "N3xnDIWv5cxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(tweet, freqs):\n",
        "    word_l = process_tweet(tweet)\n",
        "    x = np.zeros((1, 3))\n",
        "    x[0, 0] = 1\n",
        "    for word in word_l:\n",
        "        x[0, 1] += freqs.get((word, 1.0), 0) / max(1, freqs.get((word, 1.0), 0) + freqs.get((word, 0.0), 0))\n",
        "        x[0, 2] += freqs.get((word, 0.0), 0) / max(1, freqs.get((word, 1.0), 0) + freqs.get((word, 0.0), 0))\n",
        "    return x"
      ],
      "metadata": {
        "id": "xiA_9kzT5c6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the above function"
      ],
      "metadata": {
        "id": "XzrovZcu5jwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp1 = extract_features(train_x[22], freqs)\n",
        "print(tmp1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1OQQSzm5mOb",
        "outputId": "42c9a33c-3e8f-48a0-e2bf-461a5115214f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         5.14750277 3.85249723]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid Function and Gradient Descent"
      ],
      "metadata": {
        "id": "KydShA1b6Ea7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    zz = np.negative(z)\n",
        "    h = 1 / (1 + np.exp(zz))\n",
        "    return h\n",
        "\n",
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "    m = x.shape[0]\n",
        "    for i in range(0, num_iters):\n",
        "        z = np.dot(x, theta)\n",
        "        h = sigmoid(z)\n",
        "        cost = -1. / m * (np.dot(y.transpose(), np.log(h)) + np.dot((1 - y).transpose(), np.log(1 - h)))\n",
        "        theta = theta - (alpha / m) * np.dot(x.transpose(), (h - y))\n",
        "\n",
        "    cost = float(cost)\n",
        "    return cost, theta"
      ],
      "metadata": {
        "id": "on9I_MKA6K-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Data"
      ],
      "metadata": {
        "id": "vYTO1gwc6MXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "    X_train[i, :] = extract_features(train_x[i], freqs)\n",
        "\n",
        "\n",
        "X_test = np.zeros((len(test_x), 3))\n",
        "for i in range(len(test_x)):\n",
        "    X_test[i, :] = extract_features(test_x[i], freqs)\n",
        "\n",
        "J, theta = gradientDescent(X_train, train_y, np.zeros((3, 1)), 1e-9, 15000)"
      ],
      "metadata": {
        "id": "YzOp9H0W54Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Input:\n",
        "        tweet: a string\n",
        "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "        theta: (3,1) vector of weights\n",
        "    Output:\n",
        "        y_pred: the probability of a tweet being positive or negative\n",
        "        # if y_pred > 0.5 => Positive\n",
        "        # else => Negative"
      ],
      "metadata": {
        "id": "deBNpYDp55C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tweet(tweet, freqs, theta):\n",
        "    x = extract_features(tweet, freqs)\n",
        "    y_pred = sigmoid(np.dot(x, theta))\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "e9zQrSPC6c3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Input:\n",
        "        test_x: a list of tweets\n",
        "        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
        "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
        "        theta: weight vector of dimension (3, 1)\n",
        "    Output:\n",
        "        accuracy: (# of tweets classified correctly) / (total # of tweets)"
      ],
      "metadata": {
        "id": "_7yVc3vm6fPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
        "    y_hat = []\n",
        "    for tweet in test_x:\n",
        "        y_pred = predict_tweet(tweet, freqs, theta)\n",
        "        if y_pred > 0.5:\n",
        "            y_hat.append(1)\n",
        "        else:\n",
        "            y_hat.append(0)\n",
        "\n",
        "    accuracy = (y_hat == np.squeeze(test_y)).sum() / len(test_x)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "hsYsWksG6fjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the above functions\n",
        "\n",
        "      Accuracy = Correct Predictions / Total Predictions"
      ],
      "metadata": {
        "id": "jM_GYUkA6nYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
        "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5jiwYu86mmH",
        "outputId": "11b03cdc-7d3a-4cc1-ce88-9797054049ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression model's accuracy = 0.6370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## kNN Test Function"
      ],
      "metadata": {
        "id": "Pco-ZRI77TJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_knn(test_x, test_y, knn):\n",
        "    y_pred = knn.predict(X_test)\n",
        "    accuracy = accuracy_score(test_y, y_pred)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "tyNi3O7E67Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize kNN Classifier and Fit"
      ],
      "metadata": {
        "id": "akTDzsm5_Cnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 19\n",
        "knn = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)\n",
        "knn.fit(X_train, np.squeeze(train_y))"
      ],
      "metadata": {
        "id": "rxGXZcak_C2R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "b7b4e314-52be-4a27-e62a-dd0f1c0ecba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_jobs=-1, n_neighbors=19)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_jobs=-1, n_neighbors=19)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_jobs=-1, n_neighbors=19)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the Above Functions"
      ],
      "metadata": {
        "id": "IH5PcCne_To0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_knn = test_knn(test_x, np.squeeze(test_y), knn)\n",
        "print(f\"kNN model's accuracy with k={k} = {accuracy_knn:.4f}\")"
      ],
      "metadata": {
        "id": "VXQg2wzG_Tus",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38411262-53f4-4c9a-abbf-4a21422d4261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kNN model's accuracy with k=19 = 0.7153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choosing the Right K"
      ],
      "metadata": {
        "id": "hNRy2NnpGMIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for k in range(1, 51, 2):\n",
        "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "    classifier.fit(X_train, np.squeeze(train_y))\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    accuracy_knn = test_knn(test_x, np.squeeze(test_y), classifier)\n",
        "    results.append([k, accuracy_knn])\n",
        "    print (\"k=\",k,\" Accuracy=\", accuracy_knn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDL0eWsvFS1Y",
        "outputId": "77ed5a20-6212-488b-a3ea-8a0679318d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k= 1  Accuracy= 0.67325\n",
            "k= 3  Accuracy= 0.6985\n",
            "k= 5  Accuracy= 0.70425\n",
            "k= 7  Accuracy= 0.70175\n",
            "k= 9  Accuracy= 0.7045\n",
            "k= 11  Accuracy= 0.707\n",
            "k= 13  Accuracy= 0.71075\n",
            "k= 15  Accuracy= 0.71175\n",
            "k= 17  Accuracy= 0.71375\n",
            "k= 19  Accuracy= 0.71525\n",
            "k= 21  Accuracy= 0.71525\n",
            "k= 23  Accuracy= 0.71625\n",
            "k= 25  Accuracy= 0.716\n",
            "k= 27  Accuracy= 0.71625\n",
            "k= 29  Accuracy= 0.71675\n",
            "k= 31  Accuracy= 0.7175\n",
            "k= 33  Accuracy= 0.717\n",
            "k= 35  Accuracy= 0.7175\n",
            "k= 37  Accuracy= 0.71825\n",
            "k= 39  Accuracy= 0.71625\n",
            "k= 41  Accuracy= 0.71925\n",
            "k= 43  Accuracy= 0.71725\n",
            "k= 45  Accuracy= 0.71775\n",
            "k= 47  Accuracy= 0.71725\n",
            "k= 49  Accuracy= 0.71725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now let's predict new data using kNN and Logistic regression"
      ],
      "metadata": {
        "id": "nvJ7ND5G_hUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *New Input*"
      ],
      "metadata": {
        "id": "JdbKIpmy_lS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tweet = 'i am happy'"
      ],
      "metadata": {
        "id": "xKHKNer7_ruC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *kNN*"
      ],
      "metadata": {
        "id": "sjLIC9IJ_8_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = extract_features(my_tweet, freqs)\n",
        "predicted_sentiment_knn = knn.predict(x)\n",
        "\n",
        "if predicted_sentiment_knn == 1:\n",
        "    print('kNN prediction: Positive sentiment')\n",
        "else:\n",
        "    print('kNN prediction: Negative sentiment')"
      ],
      "metadata": {
        "id": "eITBLWrl_uf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0b59e5c-f002-48cc-fefc-06c2fca79b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kNN prediction: Positive sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Logistic Regression*"
      ],
      "metadata": {
        "id": "SfJNIy6UABnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre(sentence):\n",
        "    yhat = predict_tweet(sentence, freqs, theta)\n",
        "    if yhat > 0.5:\n",
        "        return 'Positive sentiment'\n",
        "    else:\n",
        "        return 'Negative sentiment'\n",
        "\n",
        "res = pre(my_tweet)\n",
        "print(f\"Logistic regression prediction: {res}\")"
      ],
      "metadata": {
        "id": "a7YGjMSk_5gn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7bf0dcf-2e9f-47b8-85e6-461c77bf7b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression prediction: Positive sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What if we input:\n",
        "    I am NOT happy!"
      ],
      "metadata": {
        "id": "foJWwcbqYi-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tweet = 'I am NEVER happy'\n",
        "\n",
        "x = extract_features(my_tweet, freqs)\n",
        "predicted_sentiment_knn = knn.predict(x)\n",
        "\n",
        "if predicted_sentiment_knn == 1:\n",
        "    print('kNN prediction: Positive sentiment')\n",
        "else:\n",
        "    print('kNN prediction: Negative sentiment')\n",
        "\n",
        "def pre(sentence):\n",
        "    yhat = predict_tweet(sentence, freqs, theta)\n",
        "    if yhat > 0.5:\n",
        "        return 'Positive sentiment'\n",
        "    else:\n",
        "        return 'Negative sentiment'\n",
        "\n",
        "res = pre(my_tweet)\n",
        "print(f\"Logistic regression prediction: {res}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5-aQBPcYqzk",
        "outputId": "ef0946d5-e40a-4393-a799-33af9ddd9a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kNN prediction: Positive sentiment\n",
            "Logistic regression prediction: Positive sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Process the data (with negation)\n",
        "\n",
        "Why is the original processing giving an obviously negative sentiment a positive output?\n",
        "\n",
        "Feature extraction does not differentiate \"happy\" and \"not happy\". They are both treated like \"happy\" which has a high positive sentiment. To fix this we attempt to change the data preprocessing part to handle negations like \"not\", \"no\", \"never\", and \"n't\"."
      ],
      "metadata": {
        "id": "CbuWAbloY_o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tweet(tweet):\n",
        "    from nltk.stem.porter import PorterStemmer\n",
        "    import string\n",
        "    import re\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    tokenizer = nltk.TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    negation = False\n",
        "    for word in tweet_tokens:\n",
        "        if word in [\"not\", \"no\", \"never\", \"n't\"]:\n",
        "            negation = True\n",
        "            continue\n",
        "        if negation and (word not in stopwords_english and word not in string.punctuation and  is_number(word)==False):\n",
        "            word = \"NEG_\" + word\n",
        "            negation = False\n",
        "        if word not in stopwords_english and word not in string.punctuation and is_number(word)==False:\n",
        "            stem_word = stemmer.stem(word)\n",
        "            tweets_clean.append(stem_word)\n",
        "    return tweets_clean"
      ],
      "metadata": {
        "id": "lbJIUs1yZv4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Re-run the rest of the code"
      ],
      "metadata": {
        "id": "8gyZuikpZ5Ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos = all_positive_tweets[:4000]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n",
        "\n",
        "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)\n",
        "\n",
        "freqs = build_freqs(train_x, train_y)\n",
        "\n",
        "tmp1 = extract_features(train_x[22], freqs)\n",
        "\n",
        "X_train = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "    X_train[i, :] = extract_features(train_x[i], freqs)\n",
        "\n",
        "X_test = np.zeros((len(test_x), 3))\n",
        "for i in range(len(test_x)):\n",
        "    X_test[i, :] = extract_features(test_x[i], freqs)\n",
        "\n",
        "J, theta = gradientDescent(X_train, train_y, np.zeros((3, 1)), 1e-9, 15000)\n",
        "\n",
        "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, theta)\n",
        "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")\n",
        "\n",
        "k = 20\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "knn.fit(X_train, np.squeeze(train_y))\n",
        "\n",
        "accuracy_knn = test_knn(test_x, np.squeeze(test_y), knn)\n",
        "print(f\"kNN model's accuracy with k={k} = {accuracy_knn:.4f}\")\n",
        "\n",
        "my_tweet = 'I am NOT happy'\n",
        "\n",
        "x = extract_features(my_tweet, freqs)\n",
        "predicted_sentiment_knn = knn.predict(x)\n",
        "\n",
        "if predicted_sentiment_knn == 1:\n",
        "    print('kNN prediction: Positive sentiment')\n",
        "else:\n",
        "    print('kNN prediction: Negative sentiment')\n",
        "\n",
        "def pre(sentence):\n",
        "    yhat = predict_tweet(sentence, freqs, theta)\n",
        "    if yhat > 0.5:\n",
        "        return 'Positive sentiment'\n",
        "    else:\n",
        "        return 'Negative sentiment'\n",
        "\n",
        "res = pre(my_tweet)\n",
        "print(f\"Logistic regression prediction: {res}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7KIuqnVaGJu",
        "outputId": "9c49abae-c400-4b22-c7df-7f25ae079c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-9b94576fade0>:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  cost = float(cost)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression model's accuracy = 0.6592\n",
            "kNN model's accuracy with k=20 = 0.7003\n",
            "kNN prediction: Negative sentiment\n",
            "Logistic regression prediction: Negative sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why did the accuracy change?\n",
        "\n",
        "Initially, the model was trained on dataset 1 with the first pre-processing function. The two models perform well because it learns strong corelations between individual words like \"happy\" and \"sad\". They both score around 92% in accuracy with kNN being slightly better.\n",
        "\n",
        "However, it was noted that the model with the first pre-processing function disregards stopwords like \"not\". This means that statements such as \"I am not happy\" will be considered to have positive sentiment as the model will only consider \"happy\" => \"happi\".\n",
        "\n",
        "Therefore, the model was altered with the second pre-processing function differentiates between \"happy\" => \"happi\" and \"not happy\" => \"NEG_happi\".\n",
        "\n",
        "  The model was tested with Dataset1, but was still not able to detect \"not happy\" as a negative sentiment. After analysis, it was clear  that Dataset 1 is insufficient to train the model to handle negation.\n",
        "\n",
        "Thus, Dataset2 was used with twice the positive and negative tweets, and after training the model , it was able to correctly identify \"not happy\" => \"NEG_happi\" as  a negative sentiment.\n",
        "\n",
        "## Why did the change in the Dataset lead to a drop in the accuracy?\n",
        "\n",
        "The accuracy of logistic regression dropped to around 60% and kNN to 70%.\n",
        "\n",
        "The algorithm for the sentiment analysis used by the model is inherently simple, meaning it does not work well with more complex data as well as varying tweets as is the case with Dataset 2 and handling negation.\n",
        "\n",
        "Overall, kNN was a slightly better model."
      ],
      "metadata": {
        "id": "JeMUEU8sbLT9"
      }
    }
  ]
}